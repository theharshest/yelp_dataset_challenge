# -*- coding: utf-8 -*-
"""
Utilities for doing "walk forward optimization".

Created on Sun Nov 30 09:51:14 2014

@author: John Maloney
"""

import time
import feat_info as fi
import datautils as du
import jsonutils as ju
import numpy as np
import sklearn.metrics as metrics

'''
Estimate the generalization error rate using the "walk forward optimization"
approach.

Inputs:

  c:
    the classifier to be tested

  all_buses:
    all the business objects available for generating train and test datasets

  all_reviews:
    all the review objects available for generating train and test datasets

  all_tips:
    all the tip objects available for generating train and test datasets

Outputs:

  results:
    a list of tuples, one tuple for each round of cross validation, the first
    element in each tuple provides the true values for that round's test examples
    and the second element provides the predictions generated by the classifier
    on that round's test examples
'''
def wfocv(c, all_buses, all_reviews, all_tips, time_delta):
    # find the earliest and latest review dates
    start_date = int(time.time())
    end_date = 0
    
    for bus in all_buses:
        first_review_date = bus[fi.first_review_date]
        last_review_date = bus[fi.last_review_date]
        if (first_review_date < start_date):
            start_date = first_review_date
        if (last_review_date > end_date):
            end_date = last_review_date

    
    # initialize the "prediction date"
    pdate = start_date + du.year

    # generate the first training set
    buses_train = du.gen_dataset(pdate, all_buses, all_reviews, all_tips)
    X_train,y_train = ju.json2xy(buses_train, fi.data_feat_info, fi.label)

    # update prediction date
    pdate = pdate + time_delta

    # generate the first test set
    buses_test = du.gen_dataset(pdate, all_buses, all_reviews, all_tips)    
    X_test,y_test = ju.json2xy(buses_test, fi.data_feat_info, fi.label)

    # initialize the stop_date threshold
    stop_date = end_date - time_delta

    # create list to hold results
    results = []

    # perform "walk forward optimization"
    while (pdate <= stop_date):
        # train the classifier
        c = c.fit(X_train, y_train)
        
        # collect predictions from the classifier
        y_pred = predict(c, X_test)

        # save results
        results.append((y_test, y_pred))

        print '\nMetrics for prediction date %s:\n' % du.date2str(du.int2date(pdate))
        print(metrics.classification_report(y_test, y_pred, target_names=fi.class_names))

        # update the prediction date for the next round
        pdate = pdate + time_delta

        # use current test set as training set for next round
        X_train = X_test
        y_train = y_test
        
        # generate a new test set for next round
        buses_test = du.gen_dataset(pdate, all_buses, all_reviews, all_tips)    
        X_test,y_test = ju.json2xy(buses_test, fi.data_feat_info, fi.label)
    #end while

    # return the true values and predictions for each round
    return results
#end wfocv

'''
Use the specified classifier to make predictions on the provided examples.

Inputs:

  c:
    the classifier to use to make predictions

  X_test:
    the test examples

Outputs:

  y_pred:
    the predicted labels for each test example
'''
def predict(c, X_test):
    
    # get number of test exampls
    N = X_test.shape[0]
    
    # initialize array to collect predictions
    y_pred = np.zeros(N)

    # test the classifier
    for i in xrange(N):
        y_pred[i] = c.predict(X_test[i,:])

    # return the predictions
    return y_pred