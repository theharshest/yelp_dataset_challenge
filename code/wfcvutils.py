# -*- coding: utf-8 -*-
"""
Utilities for doing "walk forward cross validation".

Created on Sun Nov 30 09:51:14 2014

@author: John Maloney
"""

import time
import feat_info as fi
import datautils as du
import jsonutils as ju
import numpy as np
import sklearn.metrics as metrics
import sklearn.grid_search as grid_search
import sklearn.decomposition as decomp
import sklearn.preprocessing as prep

'''
Estimate the generalization error rate using the "walk forward cross validation"
approach.

Inputs:

  clf:
    the classifier to be tested

  param_grid:
    dictionary with parameters names (string) as keys and lists of parameter
    settings to try as values, or a list of such dictionaries, in which case
    the grids spanned by each dictionary in the list are explored. This enables
    searching over any sequence of parameter settings

  all_buses:
    all the business objects available for generating train and test datasets

  all_reviews:
    all the review objects available for generating train and test datasets

  all_tips:
    all the tip objects available for generating train and test datasets

  init_pdate:
    the initial prediction date to use (in seconds since the epoch)

  time_delta:
    the amount of time between training prediction date and test prediction
    date (in seconds)

  feat_info: (optional)
    the list of features to use for classification (default is feat_info.data_feat_info)

  std_data: (optional)
    if True then the data is standardized to have mean zero and standard deviation
    one (default is True)

  usamp: (optional)
    if True then the "still open" class is under-sampled (default is True)

  binary: (optional)
    specifies the list of classes to treat as the positive class in a binary
    classification problem, the remaining classes are treated as the negative
    class, if not specified then data is generated for a multi-class
    classification problem (default is None)

  pca: (optional)
    indicates whether PCA should be used to reduce the dimension of the data:
      pca < 0 - don't use PCA (default)
      pca = 0 - use PCA without limiting the number of components
      pca > 0 - use PCA and limit the number of components to the value specified

Outputs:

  results:
    a list of tuples, one tuple for each round of cross validation, the first
    element in each tuple provides the true values for that round's test examples
    and the second element provides the predictions generated by the classifier
    on that round's test examples
'''
def wfcv(clf, param_grid, all_buses, all_reviews, all_tips, init_pdate, time_delta,
         feat_info=fi.data_feat_info, std_data=True, usamp=True, binary=None, pca=-1):
    # find the earliest and latest review dates
    start_date = int(time.time())
    end_date = 0
    for bus in all_buses:
        first_review_date = bus[fi.first_review_date]
        last_review_date = bus[fi.last_review_date]
        if (first_review_date < start_date):
            start_date = first_review_date
        if (last_review_date > end_date):
            end_date = last_review_date

    # print out earliest and latest dates
    print('Earliest review date: %s' % du.date2str(du.int2date(start_date)))
    print('Latest review date:   %s' % du.date2str(du.int2date(end_date)))
    
    # initialize the "prediction date"
    pdate = init_pdate

    # create variables for the training data - it will be populated later
    X_train_orig,y_train = None,None

    # generate the first data set
    buses_test = du.gen_dataset(pdate, all_buses, all_reviews, all_tips, usamp=usamp, binary=binary)    
    X_test_orig,y_test = ju.json2xy(buses_test, feat_info, fi.label, std=False)
    
    print('Number of attributes in data set: %d' % X_test_orig.shape[1])

    # initialize the stop_date threshold
    stop_date = end_date - 2*time_delta

    # create list to hold results
    results = []

    # configure scoring metric to be used during grid search and feature selection
    # - select a metric that is suited to unbalanced classification
    scorer = 'f1'

    # perform "walk forward cross validation"
    while (pdate <= stop_date):
        print('\n===================================================================')
        print("Train classifier using train set with prediction date %s:" % du.date2str(du.int2date(pdate)))
        # update the prediction date for the this round
        pdate = pdate + time_delta

        # use current test set as training set for this round
        X_train_orig = X_test_orig
        y_train = y_test

        # generate a new test set for this round
        buses_test = du.gen_dataset(pdate, all_buses, all_reviews, all_tips, usamp=usamp, binary=binary)    
        X_test_orig,y_test = ju.json2xy(buses_test, feat_info, fi.label, std=False)

        # by default, use the original untransformed X data
        # - X_train & X_test will contain the transformed data (if any transformation is done)
        X_train = X_train_orig
        X_test = X_test_orig

        # ===========================================
        # apply any requested data transformations

        # standardize the data
        # See http://scikit-learn.org/stable/modules/preprocessing.html
        if (std_data):
            print('  Standardize the data...')
            # scaler is trained on training set
            scaler = prep.StandardScaler().fit(X_train_orig)
            # scaler is used to transform both train and test data
            X_train = scaler.transform(X_train_orig)
            X_test = scaler.transform(X_test_orig)

        # reduce the dimension of the data using PCA
        # See http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html#example-applications-face-recognition-py
        if (pca >= 0):
            print('  Reduce dimension using PCA...')
            if (pca == 0):
                pca = None
            rand_pca = decomp.RandomizedPCA(n_components=pca, whiten=True)
            # fit PCA on the training data
            rand_pca.fit(X_train)
            # transform train and test sets using PCA
            X_train = rand_pca.transform(X_train)
            X_test  = rand_pca.transform(X_test)
            print('    featues remaining after PCA: %d' % X_train.shape[1])

        # data transformations complete
        # ===========================================

        # use grid search to train and test the classifier:
        # - see http://scikit-learn.org/stable/auto_examples/grid_search_digits.html#example-grid-search-digits-py

        # train the classifier using grid search
        gs = grid_search.GridSearchCV(clf, param_grid, n_jobs=-1, scoring=scorer)
        #gs = grid_search.GridSearchCV(clf, param_grid, scoring=scorer)
        gs.fit(X_train, y_train)

        print("\nBest parameters set found on train set:\n")
        print(gs.best_estimator_)
        print("\nGrid scores on train set:\n")
        for params, mean_score, scores in gs.grid_scores_:
            print("  %0.3f (+/-%0.03f) for %r"
              % (mean_score, scores.std() / 2, params))

        # collect predictions from the classifier
        y_pred = gs.predict(X_test)

        # print out the confusion matrix
        print("\nResults for test set with prediction date %s:\n" % du.date2str(du.int2date(pdate)))
        cm = metrics.confusion_matrix(y_test, y_pred)
        print_cm(cm)

        #print("\nScores on evaluation set:\n")
        #print(metrics.classification_report(y_test, y_pred, target_names=fi.class_names))

        # save results
        results.append((y_test, y_pred))
    #end while

    # return the true values and predictions for each round
    return results
#end wfocv

'''
Print out the confusion matrix.
'''
def print_cm(cm):
    dashes = "-------"
    # generate & print header
    K = cm.shape[0]
    hdr1 = "|" + "".center(9) + "|"
    hdr2 = "|" + dashes.center(9) + "|"
    for k in xrange(K):
        hdr1 += ("class %d" % k).center(9) + "|"
        hdr2 += (dashes).center(9) + "|"
    hdr1 += ("totals").center(9) + "|"
    hdr2 += (dashes).center(9) + "|"
    print(hdr2)
    print(hdr1)
    print(hdr2)
    # generate & print each row
    for j in xrange(K):
        row = "|" + ("class %d" % j).center(9) +"|"
        row_tot = np.sum(cm[j,:], dtype=float)
        for k in xrange(K):
            pcnt = (float(cm[j,k])/row_tot)*100
            row += ("%6.2f%%" % pcnt).center(9) + "|"
        row += ("%6d" % np.sum(cm[j,:])).center(9) + "|"
        print(row)
    # generate and print bottom sum row
    print(hdr2)
    totals = np.sum(cm,axis=0)
    row = "|" + "totals".center(9) + "|"
    for t in totals:
        row += ("%6d" % t).center(9) + "|"
    row += ("%6d" % np.sum(np.sum(cm))).center(9) + "|"
    print(row)
    print(hdr2)